# TO-DO
- Update README
- Test more and update "Insights" tab
- look into grad-cam and saliency maps for vgg
- undertstand and explan gram matrices better. update the home page. are they always square?

Visualizations
‚óè Diffusion Randomized Input Sampling
Explanation (DF-RISE) 
‚óè Diffusion Gradient-Weighted Class
Activation Mapping (DF-CAM)
‚óè Exponential Time-Step Sampling
‚óè Relevance Score

DAAM Process

- Better streamlit slider progress bars. they should be updated or vanish!
- Style transfer/reconstruct is very slow. why

## Implementing Grad-CAM
In Neural Style Transfer (NST), an image is being optimized to match both the style of a style image and the content of a content image. The network not being used for tasks like classification, but rather to extract content and style features at different layers. Thus, Grad-CAM and Activation Atlases will be applied to the intermediate feature maps that come from these layers during the optimization process.

Grad-CAM helps visualize the areas of the input image that are influencing the loss function at each layer. 

---------------------------------------------------

# Neural Style Transfer Visualization App

## üìù Project Overview

### What is Neural Style Transfer?
Neural Style Transfer (NST) is a computer vision technique that allows you to reimagine images by blending the content of one image with the artistic style of another. Imagine taking a photograph and rendering it in the style of a Van Gogh painting or a Picasso cubist composition!

### Key Features of This Application
- **Content Reconstruction**: Understand how neural networks perceive and reconstruct image content
- **Style Reconstruction**: Visualize how networks capture artistic styles through Gram matrices
- **Interactive Style Transfer**: Blend content and style images with real-time parameter tuning
- **Comprehensive Insights**: Explore the technical nuances of the NST process

## üõ† Technical Architecture

### Core XAI Components
1. **Streamlit Interface**: `nst_app.py`
   - Provides an interactive, user-friendly web application
   - Allows real-time parameter manipulation. Helps analyze how sensitive the output of the neural network is to different models, optimizers, layers and parameters.
   - Prints out Style/Content Loss. Monitoring the evolution of losses during the optimization process gives insight into how the image is evolving to meet both objectives.
   - Decomposition of Style and Content Reconstruction for better understanding of how the model separates content from style. Visualizes feature maps and Gram Matrices to provide insights on the latent space of the neural network.s
   - Visualizes style transfer processes

2. **Image Processing**:
   - Uses PyTorch for tensor operations
   - Leverages pre-trained VGG16 and VGG19 networks


## üîß Installation

### Prerequisites
- Python 3.8+
- pip or conda

### Setup Steps
```bash
# Clone the repository
git clone https://github.com/Sakshee5/XAI-style-transfer.git
cd XAI-style-transfer

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # On Windows

# Install dependencies
pip install -r requirements.txt

# Run the Streamlit app
streamlit run nst_app.py
```

## üéõ Key Parameters and Their Effects

### Content Weight
- **Range**: 10¬≥ to 10‚Å∂
- **Purpose**: Controls how closely the output resembles the original content image
- **Higher Values**: Preserve more structural details
- **Lower Values**: Allow more stylistic interpretation

### Style Weight
- **Range**: 10¬≥ to 10‚Åµ
- **Purpose**: Determines the influence of the style image
- **Higher Values**: More pronounced artistic style
- **Lower Values**: Subtler style transfer

### Total Variation Weight
- **Range**: 0.0 to 10.0
- **Purpose**: Reduces noise and smooths the output image
- **Higher Values**: Smoother, potentially less detailed image
- **Lower Values**: Potentially noisier but more detailed result

## üß† Technical Deep Dive

### Feature Extraction
- Uses convolutional layers from VGG networks
- Early layers capture low-level features (edges, textures)
- Deeper layers capture high-level semantic information

### Loss Calculation
1. **Content Loss**: Measures structural similarity
2. **Style Loss**: Captures texture and color distributions via Gram matrices
3. **Total Variation Loss**: Encourages image smoothness

## üöÄ Performance Optimization

### Optimizer Choices
1. **LBFGS (Limited-memory BFGS)**: More precise, Memory-intensive, Faster convergence

2. **Adam**: Computationally efficient, Longer convergence time, More stable for larger networks

## üî¨ Experimental Insights

### Recommended Experiments
1. Try different feature map indices
2. Explore various initialization methods
3. Compare VGG16 vs VGG19 performance